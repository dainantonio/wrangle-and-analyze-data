{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Data Wrangling](#data wrangling)\n",
    "    * [Gathering](#gathering)\n",
    "    * [Assessing](#assessing)\n",
    "    * [Cleaning](#cleaning)\n",
    "* [Storing](#storing)\n",
    "* [Exploratory Data Analysis](#exploratory data analysis)   \n",
    "* [Conclusion](#conclusion)\n",
    "* [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Real-world data rarely comes clean. Using Python and its libraries, I gathered data from a variety of sources and in a variety of formats, assessed its quality and tidiness, then cleaned it. \n",
    "\n",
    "### Softwares needed:\n",
    "> The following packages (libraries) need to be installed. You can install these packages via conda or pip. \n",
    "\n",
    "* pandas\n",
    "* NumPy\n",
    "* requests\n",
    "* tweepy\n",
    "* json\n",
    "\n",
    "> A text editor, like VS Code or Atom.\n",
    "A terminal application (Terminal on Mac and Linux or Cygwin on Windows).\n",
    "\n",
    "### Dataset\n",
    "\n",
    "> The dataset that I wrangled (analyzed and visualized) was the tweet archive of Twitter user @dog_rates, also known as WeRateDogs.  \n",
    "\n",
    "> These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "\n",
    "> This archive contains basic tweet data ('tweet ID', 'timestamp', 'text', etc.) for all 5000+ of their tweets as they stood on August 1, 2017. More on this soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> My goal was to wrangle this Twitter data in order to create interesting and trustworthy analyses and visualizations. However, we had to gather more data (\"retweet count\" and \"favorite count\") to get the best analysis and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get started!\n",
    "> Before we start buid the project We set up the import statements for all of the packages we plan to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "# import library for making HTTP requests\n",
    "import requests\n",
    "import json\n",
    "# import os(operating system) library to store file\n",
    "import os\n",
    "\n",
    "# 'magic word' so that your visualizations are plotted\n",
    "%matplotlib inline\n",
    "print(\"Set up complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering the Data\n",
    "Data was gathered from three data sources.\n",
    "1. Download and load csv file data manually into DataFrame.\n",
    "2. Download and load tweet image predictions programatically into DataFrame.\n",
    "3. Webscraping data using API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Download and load csv file data manually into DataFrame.\n",
    "> The WeRateDogs Twitter archive provided by Udacity. File `twitter_archive_enhanced.csv`downloaded manually and then loaded and opened into pandas DataFrame `arch_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-31 00:18:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891815181...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-30 15:58:51 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891689557...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Darla</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-29 16:00:24 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Franklin. He would like you to stop ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891327558...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "2  891815181378084864                    NaN                  NaN   \n",
       "3  891689557279858688                    NaN                  NaN   \n",
       "4  891327558926688256                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "2  2017-07-31 00:18:03 +0000   \n",
       "3  2017-07-30 15:58:51 +0000   \n",
       "4  2017-07-29 16:00:24 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                  NaN   \n",
       "3  This is Darla. She commenced a snooze mid meal...                  NaN   \n",
       "4  This is Franklin. He would like you to stop ca...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "2  https://twitter.com/dog_rates/status/891815181...                12   \n",
       "3  https://twitter.com/dog_rates/status/891689557...                13   \n",
       "4  https://twitter.com/dog_rates/status/891327558...                12   \n",
       "\n",
       "   rating_denominator      name doggo floofer pupper puppo  \n",
       "0                  10   Phineas  None    None   None  None  \n",
       "1                  10     Tilly  None    None   None  None  \n",
       "2                  10    Archie  None    None   None  None  \n",
       "3                  10     Darla  None    None   None  None  \n",
       "4                  10  Franklin  None    None   None  None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the twitter archived data for WeRateDogs into dataframe\n",
    "arch_df = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "arch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2356 non-null   int64  \n",
      " 1   in_reply_to_status_id       78 non-null     float64\n",
      " 2   in_reply_to_user_id         78 non-null     float64\n",
      " 3   timestamp                   2356 non-null   object \n",
      " 4   source                      2356 non-null   object \n",
      " 5   text                        2356 non-null   object \n",
      " 6   retweeted_status_id         181 non-null    float64\n",
      " 7   retweeted_status_user_id    181 non-null    float64\n",
      " 8   retweeted_status_timestamp  181 non-null    object \n",
      " 9   expanded_urls               2297 non-null   object \n",
      " 10  rating_numerator            2356 non-null   int64  \n",
      " 11  rating_denominator          2356 non-null   int64  \n",
      " 12  name                        2356 non-null   object \n",
      " 13  doggo                       2356 non-null   object \n",
      " 14  floofer                     2356 non-null   object \n",
      " 15  pupper                      2356 non-null   object \n",
      " 16  puppo                       2356 non-null   object \n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# raw datset summary that displays missing values in each column\n",
    "arch_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download and load tweet image predictions programatically into DataFrame.\n",
    "> File `image_predictions.tsv` is hosted on Udacity's servers and was downloaded programmatically using the `requests` library and the following URL:https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>True</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.360687</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.222752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>True</td>\n",
       "      <td>Doberman</td>\n",
       "      <td>0.154629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "2  666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg   \n",
       "3  666044226329800704  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg   \n",
       "4  666049248165822465  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "2        1         German_shepherd  0.596461    True            malinois   \n",
       "3        1     Rhodesian_ridgeback  0.408143    True             redbone   \n",
       "4        1      miniature_pinscher  0.560311    True          Rottweiler   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  \n",
       "2  0.138584    True           bloodhound  0.116197    True  \n",
       "3  0.360687    True   miniature_pinscher  0.222752    True  \n",
       "4  0.243682    True             Doberman  0.154629    True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `requests` module allows you to send HTTP requests\n",
    "import requests\n",
    "\n",
    "# url of image prediction tsv file\n",
    "url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "\n",
    "# send HTTP request to URL and save the response from server in a response object called r.\n",
    "r = requests.get(url) \n",
    "with open(url.split('/')[-1], mode = 'wb') as file:\n",
    "    file.write(r.content)\n",
    "\n",
    "# Import data from the tsv file to a pandas DataFrame `img_df`.\n",
    "img_df = pd.read_csv('image-predictions.tsv', sep = ('\\t'))\n",
    "# print dataframe\n",
    "img_df.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>https://pbs.twimg.com/media/DF6hr6BUMAAzZgT.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>basset</td>\n",
       "      <td>0.555712</td>\n",
       "      <td>True</td>\n",
       "      <td>English_springer</td>\n",
       "      <td>0.225770</td>\n",
       "      <td>True</td>\n",
       "      <td>German_short-haired_pointer</td>\n",
       "      <td>0.175219</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>https://pbs.twimg.com/media/DF_q7IAWsAEuuN8.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>paper_towel</td>\n",
       "      <td>0.170278</td>\n",
       "      <td>False</td>\n",
       "      <td>Labrador_retriever</td>\n",
       "      <td>0.168086</td>\n",
       "      <td>True</td>\n",
       "      <td>spatula</td>\n",
       "      <td>0.040836</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>https://pbs.twimg.com/media/DGBdLU1WsAANxJ9.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>0.716012</td>\n",
       "      <td>True</td>\n",
       "      <td>malamute</td>\n",
       "      <td>0.078253</td>\n",
       "      <td>True</td>\n",
       "      <td>kelpie</td>\n",
       "      <td>0.031379</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>https://pbs.twimg.com/media/DGGmoV4XsAAUL6n.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>0.323581</td>\n",
       "      <td>True</td>\n",
       "      <td>Pekinese</td>\n",
       "      <td>0.090647</td>\n",
       "      <td>True</td>\n",
       "      <td>papillon</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>orange</td>\n",
       "      <td>0.097049</td>\n",
       "      <td>False</td>\n",
       "      <td>bagel</td>\n",
       "      <td>0.085851</td>\n",
       "      <td>False</td>\n",
       "      <td>banana</td>\n",
       "      <td>0.076110</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                          jpg_url  \\\n",
       "2070  891327558926688256  https://pbs.twimg.com/media/DF6hr6BUMAAzZgT.jpg   \n",
       "2071  891689557279858688  https://pbs.twimg.com/media/DF_q7IAWsAEuuN8.jpg   \n",
       "2072  891815181378084864  https://pbs.twimg.com/media/DGBdLU1WsAANxJ9.jpg   \n",
       "2073  892177421306343426  https://pbs.twimg.com/media/DGGmoV4XsAAUL6n.jpg   \n",
       "2074  892420643555336193  https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg   \n",
       "\n",
       "      img_num           p1   p1_conf  p1_dog                  p2   p2_conf  \\\n",
       "2070        2       basset  0.555712    True    English_springer  0.225770   \n",
       "2071        1  paper_towel  0.170278   False  Labrador_retriever  0.168086   \n",
       "2072        1    Chihuahua  0.716012    True            malamute  0.078253   \n",
       "2073        1    Chihuahua  0.323581    True            Pekinese  0.090647   \n",
       "2074        1       orange  0.097049   False               bagel  0.085851   \n",
       "\n",
       "      p2_dog                           p3   p3_conf  p3_dog  \n",
       "2070    True  German_short-haired_pointer  0.175219    True  \n",
       "2071    True                      spatula  0.040836   False  \n",
       "2072    True                       kelpie  0.031379    True  \n",
       "2073    True                     papillon  0.068957    True  \n",
       "2074   False                       banana  0.076110   False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: a table full of image predictions alongside each tweet ID, image URL, and the image number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column Descriptions for the tweet image prediction table\n",
    "* tweet_id is the last part of the tweet URL after \"status/\" → https://twitter.com/dog_rates/status/889531135344209921\n",
    "\n",
    "* p1 is the algorithm's #1 prediction for the image in the tweet → golden retriever\n",
    "* p1_conf is how confident the algorithm is in its #1 prediction → 95%\n",
    "* p1_dog is whether or not the #1 prediction is a breed of dog → TRUE\n",
    "* p2 is the algorithm's second most likely prediction → Labrador retriever\n",
    "* p2_conf is how confident the algorithm is in its #2 prediction → 1%\n",
    "* p2_dog is whether or not the #2 prediction is a breed of dog → TRUE\n",
    "etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Webscraping using Tweepy API\n",
    "* Query Twitter API for each tweet's JSON data using the tweet IDs in the WeRateDogs Twitter archive.\n",
    "* Query Twitter API for each tweet's \"retweet count\" and \"favorite (\"like\") count\" at minimum, and any additional data.\n",
    "* Store each tweet's entire set of JSON data in a file called tweet_json.txt file. \n",
    "* Each tweet's JSON data should be written to its own line.\n",
    "* Then read this .txt file line by line into a pandas DataFrame with (at minimum) tweet ID, retweet count, and favorite count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# used to download from twitter's API\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "\n",
    "# https://github.com/tweepy/tweepy/blob/master/examples/oauth.py\n",
    "# == OAuth Authentication ==\n",
    "#\n",
    "# This mode of authentication is the new preferred way\n",
    "# of authenticating with Twitter.\n",
    "\n",
    "# define keys\n",
    "consumer_key = 'prDTAiUejLjznFcQfPnrsNRx8'\n",
    "consumer_secret = 'E79WpXjaIAQLbbrRyoDu9i25NILjrDv54pe0x0yJDUXV7osphO'\n",
    "access_token = '920063514063945728-5nqXAFHdlfnJhk5rrJrA4cclqelSThd'\n",
    "access_secret = 'uyVQSHbdd5aJfwvkLbNJjBd70S84v3xlVuTvmMstBhKpD'\n",
    "\n",
    "# `OAuthHandler` instance into which we pass `consumer_key` and `consumer_secret`\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "# store strings values for `access_token` and `access_key` in order to store access token\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "# Construct the API instance\n",
    "# `wait_on_rate_limit_notify` parameter added to decide whether or not to print a notification\n",
    "# when Tweepy is waiting for rate limits to replenish\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, \n",
    "                 wait_on_rate_limit_notify = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the authentication was successful, you should\n",
    "# see the name of the account print out\n",
    "print(api.me().name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Error handling in Python is done through the use of exceptions that are caught in try blocks and handled in except blocks.\n",
    "* If an error is encountered, a try block code execution is stopped and transferred down to the except block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/47612822/how-to-create-pandas-dataframe-from-twitter-search-api\n",
    "# Download Tweepy status object based on Tweet ID and store in list\n",
    "list_of_tweets = []\n",
    "# Tweets that can't be found are saved in the list below:\n",
    "cant_find_tweets_for_those_ids = []\n",
    "\n",
    "for tweet_id in arch_df['tweet_id']:   \n",
    "    # try block to test block of code for errors\n",
    "    try:\n",
    "        list_of_tweets.append(api.get_status(tweet_id))\n",
    "    # `except` block to handle the error\n",
    "    except Exception as e:\n",
    "        cant_find_tweets_for_those_ids.append(tweet_id)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweet IDs for which to gather additional data via Twitter's API\n",
    "\n",
    "print(\"The list of tweets\" ,len(list_of_tweets))\n",
    "print(\"The list of tweets no found\" , len(cant_find_tweets_for_those_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the json part of each tweepy \n",
    "my_list_of_dicts = []\n",
    "for each_json_tweet in list_of_tweets:\n",
    "    my_list_of_dicts.append(each_json_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write list into text file\n",
    "with open('tweet_json.txt', 'w') as file:\n",
    "        file.write(json.dumps(my_list_of_dicts, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame from the tweet_json.txt file\n",
    "my_demo_list = []\n",
    "with open('tweet_json.txt', encoding='utf-8') as json_file:  \n",
    "    all_data = json.load(json_file)\n",
    "    for each_dictionary in all_data:\n",
    "        tweet_id = each_dictionary['id']\n",
    "        whole_tweet = each_dictionary['text']\n",
    "        only_url = whole_tweet[whole_tweet.find('https'):]\n",
    "        favorite_count = each_dictionary['favorite_count']\n",
    "        retweet_count = each_dictionary['retweet_count']\n",
    "        created_at = each_dictionary['created_at']\n",
    "        whole_source = each_dictionary['source']\n",
    "        only_device = whole_source[whole_source.find('rel=\"nofollow\">') + 15:-4]\n",
    "        source = only_device\n",
    "        retweeted_status = each_dictionary['retweeted_status'] = each_dictionary.get('retweeted_status', 'Original tweet')\n",
    "        if retweeted_status == 'Original tweet':\n",
    "            url = only_url\n",
    "        else:\n",
    "            retweeted_status = 'This is a retweet'\n",
    "            url = 'This is a retweet'\n",
    "\n",
    "        my_demo_list.append({'tweet_id': str(tweet_id),\n",
    "                             'favorite_count': int(favorite_count),\n",
    "                             'retweet_count': int(retweet_count),\n",
    "                             'url': url,\n",
    "                             'created_at': created_at,\n",
    "                             'source': source,\n",
    "                             'retweeted_status': retweeted_status,\n",
    "                            })\n",
    "        tweet_json = pd.DataFrame(my_demo_list, columns = ['tweet_id', 'favorite_count', \n",
    "                                                       'retweet_count', 'created_at',\n",
    "                                                       'source', 'retweeted_status', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each tweet's JSON data should be written to its own line.\n",
    "* Then read this .txt file line by line into a pandas DataFrame with (at minimum) tweet ID, retweet count, and favorite count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing Data for this Project\n",
    "After gathering each of the above pieces of data, assess them visually and programmatically for quality and tidiness issues. Detect and document at least eight (8) quality issues and two (2) tidiness issues in your wrangle_act.ipynb Jupyter Notebook. To meet specifications, the issues that satisfy the Project Motivation (see the Key Points header on the previous page) must be assessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data for this Project\n",
    "Clean each of the issues you documented while assessing. Perform this cleaning in wrangle_act.ipynb as well. The result should be a high quality and tidy master pandas DataFrame (or DataFrames, if appropriate). Again, the issues that satisfy the Project Motivation must be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing, Analyzing, and Visualizing Data for this Project\n",
    "Store the clean DataFrame(s) in a CSV file with the main one named twitter_archive_master.csv. If additional files exist because multiple tables are required for tidiness, name these files appropriately. Additionally, you may store the cleaned data in a SQLite database (which is to be submitted as well if you do).\n",
    "\n",
    "Analyze and visualize your wrangled data in your wrangle_act.ipynb Jupyter Notebook. At least three (3) insights and one (1) visualization must be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reporting for this Project\n",
    "Create a 300-600 word written report called wrangle_report.pdf or wrangle_report.html that briefly describes your wrangling efforts. This is to be framed as an internal document.\n",
    "\n",
    "Create a 250-word-minimum written report called act_report.pdf or act_report.html that communicates the insights and displays the visualization(s) produced from your wrangled data. This is to be framed as an external document, like a blog post or magazine article, for example.\n",
    "\n",
    "Both of these documents can be created in separate Jupyter Notebooks using the Markdown functionality of Jupyter Notebooks, then downloading those notebooks as PDF files or HTML files (see image below). You might prefer to use a word processor like Google Docs or Microsoft Word, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/twitter-data-in-python/\n",
    "\n",
    "https://github.com/tweepy/tweepy/blob/master/examples/oauth.py\n",
    "\n",
    "http://docs.tweepy.org/en/latest/getting_started.html\n",
    "\n",
    "https://stackoverflow.com/questions/21308762/avoid-twitter-api-limitation-with-tweepy\n",
    "\n",
    "https://stackoverflow.com/questions/47612822/how-to-create-pandas-dataframe-from-twitter-search-api\n",
    "\n",
    "https://www.pythonforbeginners.com/error-handling/python-try-and-except\n",
    "\n",
    "https://stackabuse.com/reading-and-writing-json-to-a-file-in-python/\n",
    "\n",
    "http://docs.tweepy.org/en/v3.5.0/getting_started.html#introduction\n",
    "\n",
    "https://medium.com/ub-women-data-scholars/let-the-robot-do-your-work-web-scraping-with-python-9c147fb7690f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
